%module torch_swig

%pragma(java) jniclassimports=%{
  import java.io.*;
  import java.nio.file.*;
  import com.github.fommil.jni.JniNamer;
%}

// Automatically load the library code. It's included as a resource in the jar file, so we need to
// extract the resource, write it to a temp file, then call System.load() on the temp file.
%pragma(java) jniclasscode=%{
    static {
       // This is less than ideal. Not all of the OS builds have the same dependencies, and there's no
       // OS-agnostic way that I know of to put extract the resources into a place where the normal system
       // dynamic linking logic will take over. So, instead, we try to load the superset of all possible dependencies
       // (in topological order). The call to extractAndLoadLibrary will quietly fail if any resources are not found,
       // but crash if the loaded libraries aren't enough to satisfy downstream libraries.
       // Note that if no native dependencies are available in resources, loading
       // the JNI code library may still succeed if libtorch is installed in the system-dependent standard ways.
       // As a major warning, Macs make it *very* hard to set LD_LIBRARY_PATH/DYLD_LIBRARY_PATH/etc. because
       // it wipes them whenever a process forks. This is part of System Integrity Protection.
       // The dependencies below have to be kept up-to-date with the dependencies upload in upload-libtorch-jar.sh
       // This might need to be updated if the version of libtorch is bumped (see note in the top-level README.md)
       try {
         Path tmpdir = Files.createTempDirectory("libtorch-jar-deps");

         // Open MP madness. For windows we need two libs and the libs for Linux and MacOS are weirdly named and versioned.
         NativeLoader.extractAndLoadLibrary(tmpdir, false, "libiompstubs5md.dll");
         NativeLoader.extractAndLoadLibrary(tmpdir, false, "libiomp5md.dll");
         NativeLoader.extractAndLoadLibrary(tmpdir, false, "libiomp5.dylib");
         NativeLoader.extractAndLoadLibrary(tmpdir, false, "libgomp-52f2fd74.so.1");
         // These 3 are not always present, only needed for windows
         NativeLoader.extractAndLoadLibrary(tmpdir, true, "asmjit");
         NativeLoader.extractAndLoadLibrary(tmpdir, true, "uv");
         NativeLoader.extractAndLoadLibrary(tmpdir, true, "fbgemm");

         NativeLoader.extractAndLoadLibrary(tmpdir, true, "c10");
         NativeLoader.extractAndLoadLibrary(tmpdir, true, "torch_cpu");
         NativeLoader.extractAndLoadLibrary(tmpdir, true, "torch");
         File jniFile = NativeLoader.extractAndLoadLibrary(tmpdir, false, JniNamer.getJniName("libtorch_swig.pred"));
         if (jniFile == null) {
           throw new RuntimeException("Missing resource " + JniNamer.getJniName("libtorch_swig.pred"));
         }
       } catch (IOException e) {
         throw new RuntimeException(e);
       }
    }
%}

%{
#include <type_traits>
#include <c10/core/ScalarType.h>
#include <torch/torch.h>
#include <torch/jit.h>
#include <torch/nn/init.h>
#include <torch/ordered_dict.h>
#include <torch/serialize.h>
#include <torch/cuda.h>
#include <torch/csrc/utils/cuda_lazy_init.h>


using c10::Layout;
using caffe2::TypeMeta;
using namespace at;
using namespace torch::nn::init;

/* Some utilities for throwing exceptions */


jint throwNoClassDefFoundError(JNIEnv * env, const char* message) {
  jclass exClass = env->FindClass("java/lang/NoClassDefFoundError");
  return (exClass == NULL) ? -1 : env->ThrowNew(exClass, message);
}

/** Throws a JVM-side exception with given class name (using / as package separator) and message */
jint java_throw(JNIEnv* env, const char* clss, const char* msg) {
  jclass exClass = (env)->FindClass(clss);
  return (exClass == NULL) ? throwNoClassDefFoundError(env, clss) : env->ThrowNew(exClass, msg);
}

%}

// Disables the autogenerated finalizer that calls delete. We rely on Disposer and ReferenceManager for
// memory management instead.
// TODO it would be nice if we could instead autogenerate calls to the Disposer, but it's non-trivial
%typemap(javafinalize) SWIGTYPE ""

%include "torch_primitives.i"

%include <std_string.i>
%include <std_shared_ptr.i>
%include <std_unordered_map.i>
%include <std_vector.i>
%include <std_pair.i>
%include "tuple.i"

%include "enums.swg"
%include "exception.i"


// Convert C++ exceptions into Java exceptions. This provides
// nice error messages for each listed exception, and a default
// "unknown error" message for all others.
%catches(c10::bad_optional_access, std::invalid_argument, std::runtime_error, std::out_of_range, std::logic_error, std::exception, ...);

%include "torch_string_view.i"
%include "torch_optional.i"

// These flags exist in torch declarations but we can just ignore them. We define them anyways to make
// copy-pasting from header files easier.
#ifndef C10_API
#define C10_API
#endif
#ifndef TORCH_API
#define TORCH_API
#endif
#ifndef CAFFE2_API
#define CAFFE2_API
#endif
#ifndef TORCH_CUDA_API
#define TORCH_CUDA_API
#endif
// swig doesn't understand final
#define final

// approximation of TORCH_ARG for swig
// swig doesn't understand the use of decltype(*this) so we have to painfully specify the name
// ourselves
%define TORCH_ARG(C, T, name)
  C name(T name);
  T name();
%enddef


// Sometimes the const reference leads to issues with swig, so we have a version where it's by value
%define TORCH_VALUE_ARG(C, T, name)
  C name(T name);
  const T name();
%enddef

// torch has some optional properties. this wraps that behavior
%define TORCH_OPT_ARG(C, T, name)
  TORCH_ARG(C, T, name)
  bool has_##name() const;
  c10::optional<T> name##_opt() const;
  C name(c10::optional<T> name) const;
%enddef

%include "torch_equals_hashcode.i"

%rename(TorchTensor) Tensor;

namespace std {
%template(TensorVector)    vector<torch::Tensor>;
%template(StringVector)    vector<string>;
%template(LongPair)    pair<int64_t, int64_t>;
// TODO we should do the work to turn these into primitive arrays.
%template(DoubleVector)    vector<double>;
%template(ByteVector)    vector<char>;
%template(LongVector)    vector<int64_t>;
}

DEFINE_TUPLE_2(TensorTuple2, torch::Tensor, torch::Tensor)
DEFINE_TUPLE_2(DoubleLongTuple2, double, int64_t)
DEFINE_TUPLE_3(TensorTuple3, torch::Tensor, torch::Tensor, torch::Tensor)
DEFINE_TUPLE_4(TensorTuple4, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor)
DEFINE_TUPLE_4(TensorTuple2DoubleLong, torch::Tensor, torch::Tensor, double, int64_t)
DEFINE_TUPLE_5(TensorTuple5, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor)
DEFINE_TUPLE_5(TensorTuple4Long, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, int64_t)

%include "torch_tensor_list.i"

%include "torch_array_ref.i"
%include "torch_std_array.i"

%include "torch_data.i"

struct TensorOptions {
  TensorOptions();
  TensorOptions(Layout layout);
  TensorOptions(TypeMeta layout);
  TORCH_OPT_ARG(TensorOptions, Layout, layout)
  TORCH_OPT_ARG(TensorOptions, bool, requires_grad)
  TORCH_OPT_ARG(TensorOptions, bool, pinned_memory)
  TORCH_OPT_ARG(TensorOptions, TypeMeta, dtype)
  TORCH_OPT_ARG(TensorOptions, Device, device)
};

TO_STRING_FROM_OSTREAM(TensorOptions);

using namespace c10;

CAFFE2_API void set_num_threads(int);
CAFFE2_API void set_num_interop_threads(int);

%inline %{
bool is_cuda_available() {
  // TODO we might also want to check this (from cuda/__init__.py is_available)
  // if (not hasattr(torch._C, '_cuda_isDriverSufficient') or not torch._C._cuda_isDriverSufficient()):
  //   return False
  return torch::cuda::is_available();
}

int cuda_device_count() {
  return  torch::cuda::device_count();
}
%}

namespace torch {
namespace cuda {
bool cudnn_is_available();
}
}



DEFINE_OPTIONAL(OptScalar, torch::Scalar)
DEFINE_OPTIONAL(OptStringView, c10::string_view)
DEFINE_OPTIONAL(OptTensor, torch::Tensor)


%include "torch_generator_swig.i"

%include "torch_list.h"
DEFINE_LIST_OF_OPTIONAL(ListOptionalTensor, torch::Tensor)

%include "torch_indexing.i"

%include "torch_scalar.i"
%include "torch_tensor.i"

namespace torch {

std::string show_config();


namespace autograd {
struct AnomalyMode {
  static bool is_enabled();
  static void set_enabled(bool enabled);
};
} // namespace autograd
} // namespace torch

%include "torch_variant_enum.i"

%include "torch_init.i"

%include "torch_reduction.i"

namespace torch {
namespace nn {
namespace functional {

struct TORCH_API CrossEntropyFuncOptions {

  /// A manual rescaling weight given to each class. If given, has to be a Tensor
  /// of size C
  TORCH_ARG(CrossEntropyFuncOptions, const Tensor&, weight);
  /// Specifies a target value that is ignored
  /// and does not contribute to the input gradient.
  TORCH_ARG(CrossEntropyFuncOptions, int64_t, ignore_index);
  /// Specifies the reduction to apply to the output. Default: Mean
  TORCH_ARG(CrossEntropyFuncOptions, default_reduction_t, reduction);
};

inline Tensor cross_entropy(
    const Tensor& input,
    const Tensor& target,
    const CrossEntropyFuncOptions& options = {});

} // functional
} // nn
} // namespace torch

%inline %{


  // TODO manual_seed is broken because  at::detail::getCUDAHooks().getNumGPUs() crashes with
  // ```cufft_clear_plan_cache: expected 0 <= device_index < 0], but got device_index=140557648027168```
  // if CUDA is not available. This is a copy-paste that checks hasCUDA() first.
  // This is probably related to the fact that we compile without cuda but then use it at runtime, although
  // I'm not quite sure how.
  static inline void manual_seed_fixed(size_t seed) {
    auto gen = globalContext().defaultGenerator(DeviceType::CPU);
    {
      // See Note [Acquire lock when using random generators]
      std::lock_guard<std::mutex> lock(gen.mutex());
      gen.set_current_seed(seed);
    }
    // NB: Sometimes we build with CUDA, but we don't have any GPUs
    // available. In that case, we must not seed CUDA; it will fail!
    if (hasCUDA()) {
      for (int i = 0; i < at::detail::getCUDAHooks().getNumGPUs(); i++) {
        auto cuda_gen = globalContext().defaultGenerator(Device(at::kCUDA, i));
        {
          // See Note [Acquire lock when using random generators]
          std::lock_guard<std::mutex> lock(cuda_gen.mutex());
          cuda_gen.set_current_seed(seed);
        }
      }
    }
  }



%}

namespace at {
struct CAFFE2_API GradMode {
  static bool is_enabled();
  static void set_enabled(bool enabled);
};

} // namespace at

%include "torch_array.i"

// shared_ptr have to come before any references to their types. Think of these as "forward" declarations for stuff
// below
%shared_ptr(torch::jit::CompilationUnit)
%shared_ptr(torch::jit::Graph)

%shared_ptr(c10::Type)
%shared_ptr(c10::TupleType)
%shared_ptr(c10::ClassType)
%shared_ptr(c10::TensorType)

%include "torch_jit_type.i"
%include "torch_ir.i"
%include "torch_optim_swig.i"
%include "torch_serialize_swig.i"
%include "torch_script_swig.i"
%include "torch_profiler.i"


